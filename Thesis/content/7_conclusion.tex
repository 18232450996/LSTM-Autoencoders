\chapter{Conclusion}
\label{chap:conclusion}



Anomaly detection attracts more and more attention in the data mining field and have been applied to plenty of industrial use cases, which achieved perfect effectiveness and avoids large amount of financial spending. At the same time, the industrial applications need critically anomaly detection models under the big data background, specifically, ability to deal with high-volume, high-velocity data. In this paper, we proposed an adaptive LSTMs-autoencoder for streaming data anomaly detection. In the previous works, autoencoders are widely used in NLP tasks, e.g. language translation, sentence understanding. Vanilla autoencoders and deep autoencoders are also have been used to anomaly detection based on reconstruction error. \cite{encdecad} is the first work that use LSTMs-autoencoder for anomaly detection, with concentration to protection of temporal dependency between time series data. Our work uses similar LSTMs-autoencoder architecture, and enable the model to work with streaming data, and update model according to specific criterions. Our model shows good performance in detecting anomalies and outperforms the stationary models.\\

In terms of streaming data anomaly detection, we mainly focus on the concept drift over steam and model reinforcement by the last seen data. In the experiment with SMTP+HTTP dataset, our model shows robustness against sudden concept drift and adjusted the new data distribution very quickly. In the experiment with ForestCover dataset, the model masters serried and slight concept drifts also well. We also demonstrated an intuitive model online learning process with the small Power Demand dataset, which shows the impact of model updating between data windows in this small univariate dataset clearly.\\

Our model is designed under the assumption that there are expert labeling available during the online phase, which make the hard window collection become possible, and they are used for model updating. In the future work, a further research direction is to scale the model into fully automated without expert labeling online. Similar verification step as in \cite{threaded} could be added after online prediction to make the model prediction more reliable, so that the data labeling can be directly according to the model prediction.\\