{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from functools import reduce\n",
    "\n",
    "sys.path.insert(0, 'C:/Users/Bin/Desktop/Thesis/code')\n",
    "from Conf_EncDecAD_KDD99 import Conf_EncDecAD_KDD99\n",
    "from EncDecAD import EncDecAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration \n",
    "\n",
    "data_root = \"C:/Users/Bin/Documents/Datasets/KDD99/6_subsets_win/\"\n",
    "conf = Conf_EncDecAD_KDD99(data_root)\n",
    "#[sn_list, va_list, vn1_list, vn2_list, tn_list, ta_list] = conf.data_list\n",
    "\n",
    "#p_input = conf.p_input\n",
    "#p_inputs = conf.p_inputs\n",
    "\n",
    "\n",
    "\n",
    "batch_num = conf.batch_num\n",
    "hidden_num = conf.hidden_num\n",
    "step_num = conf.step_num\n",
    "elem_num = conf.elem_num\n",
    "\n",
    "iteration = conf.iteration\n",
    "modelpath_root = conf.modelpath_root\n",
    "modelpath = conf.modelpath\n",
    "decode_without_input = conf.decode_without_input\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1: 7.51197\n",
      "iter 2: 7.24106\n",
      "iter 3: 5.83815\n",
      "iter 4: 4.83861\n",
      "iter 5: 3.96047\n",
      "iter 6: 3.4242\n",
      "iter 7: 2.83394\n",
      "iter 8: 2.23055\n",
      "iter 9: 1.86834\n",
      "iter 10: 1.58492\n",
      "iter 11: 1.39966\n",
      "iter 12: 1.18028\n",
      "iter 13: 1.0044\n",
      "iter 14: 0.943103\n",
      "iter 15: 0.888694\n",
      "iter 16: 0.81497\n",
      "iter 17: 0.840342\n",
      "iter 18: 0.674519\n",
      "iter 19: 0.556531\n",
      "iter 20: 0.557433\n",
      "iter 21: 0.508053\n",
      "iter 22: 0.439355\n",
      "iter 23: 0.431179\n",
      "iter 24: 0.459009\n",
      "iter 25: 0.363388\n",
      "iter 26: 0.387082\n",
      "iter 27: 0.311459\n",
      "iter 28: 0.302973\n",
      "iter 29: 0.321011\n",
      "iter 30: 0.254924\n",
      "iter 31: 0.268844\n",
      "iter 32: 0.245902\n",
      "iter 33: 0.267388\n",
      "iter 34: 0.271701\n",
      "iter 35: 0.248599\n",
      "iter 36: 0.198732\n",
      "iter 37: 0.220623\n",
      "iter 38: 0.175422\n",
      "iter 39: 0.167471\n",
      "iter 40: 0.178838\n",
      "iter 41: 0.180768\n",
      "iter 42: 0.169217\n",
      "iter 43: 0.185415\n",
      "iter 44: 0.159892\n",
      "iter 45: 0.1608\n",
      "iter 46: 0.137266\n",
      "iter 47: 0.127748\n",
      "iter 48: 0.123396\n",
      "iter 49: 0.120896\n",
      "iter 50: 0.12278\n",
      "iter 51: 0.111605\n",
      "iter 52: 0.118172\n",
      "iter 53: 0.107634\n",
      "iter 54: 0.124384\n",
      "iter 55: 0.112882\n",
      "iter 56: 0.102028\n",
      "iter 57: 0.130443\n",
      "iter 58: 0.147567\n",
      "iter 59: 0.106401\n",
      "iter 60: 0.0969681\n",
      "iter 61: 0.10944\n",
      "iter 62: 0.093924\n",
      "iter 63: 0.107248\n",
      "iter 64: 0.0968959\n",
      "iter 65: 0.0901023\n",
      "iter 66: 0.101177\n",
      "iter 67: 0.0865559\n",
      "iter 68: 0.0810143\n",
      "iter 69: 0.0842896\n",
      "iter 70: 0.0751477\n",
      "iter 71: 0.0778647\n",
      "iter 72: 0.0942162\n",
      "iter 73: 0.0777883\n",
      "iter 74: 0.0967629\n",
      "iter 75: 0.0735276\n",
      "iter 76: 0.0725091\n",
      "iter 77: 0.0817166\n",
      "iter 78: 0.0919413\n",
      "iter 79: 0.0683102\n",
      "iter 80: 0.079911\n",
      "iter 81: 0.0796894\n",
      "iter 82: 0.0805593\n",
      "iter 83: 0.0766167\n",
      "iter 84: 0.0664007\n",
      "iter 85: 0.0760535\n",
      "iter 86: 0.0714242\n",
      "iter 87: 0.0729446\n",
      "iter 88: 0.0766296\n",
      "iter 89: 0.068347\n",
      "iter 90: 0.0738274\n",
      "iter 91: 0.0630006\n",
      "iter 92: 0.0713475\n",
      "iter 93: 0.0654229\n",
      "iter 94: 0.0610879\n",
      "iter 95: 0.062039\n",
      "iter 96: 0.0724365\n",
      "iter 97: 0.0717779\n",
      "iter 98: 0.0611382\n",
      "iter 99: 0.0677564\n",
      "iter 100: 0.0615055\n",
      "Model saved in file: C:/Users/Bin/Desktop/Thesis/tmp/52test/LSTMAutoencoder_kdd99_v1.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    \\n    err_vec_list = []   \\n    for _ in range(len(conf.vn1_list)//batch_num):\\n        data =[]\\n        for temp in range(batch_num):\\n            ind = np.random.randint(0,len(conf.vn1_list)-1)\\n            sub = conf.vn1_list[ind]\\n            data.append(sub)\\n        data = np.array(data)\\n        (_input_, _output_) = sess.run([input_, output_], {p_input: data})\\n        err_vec_list.append(abs(_input_ - _output_))\\n    \\n    err_vec = np.mean(np.array(err_vec_list),axis=0).reshape(batch_num,-1)\\n    mu = np.mean(err_vec,axis=0)\\n    sigma = np.cov(err_vec.T)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19e90475eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_input = tf.placeholder(tf.float32, shape=(batch_num, step_num, elem_num),name = \"p_input\")\n",
    "    p_inputs = [tf.squeeze(t, [1]) for t in tf.split(p_input, step_num, 1)]\n",
    "    \n",
    "    _enc_cell = tf.nn.rnn_cell.LSTMCell(hidden_num, use_peepholes=True)\n",
    "    _dec_cell = tf.nn.rnn_cell.LSTMCell(hidden_num, use_peepholes=True)\n",
    "    #inputs = conf.p_inputs\n",
    "    inputs = p_inputs #...\n",
    "    \n",
    "    reverse = True\n",
    "    decode_without_input = False\n",
    "    is_training = True\n",
    "    with tf.variable_scope('encoder',reuse = tf.AUTO_REUSE):\n",
    "        (z_codes, enc_state) = tf.contrib.rnn.static_rnn(_enc_cell, inputs, dtype=tf.float32)\n",
    "\n",
    "    with tf.variable_scope('decoder',reuse =tf.AUTO_REUSE) as vs:\n",
    "\n",
    "        dec_weight_ = tf.Variable(tf.truncated_normal([hidden_num,elem_num], dtype=tf.float32),name=\"dec_weight_\")\n",
    "\n",
    "        dec_bias_ = tf.Variable(tf.constant(0.1,shape=[elem_num],dtype=tf.float32),name=\"dec_bias_\")\n",
    "\n",
    "\n",
    "        dec_state = enc_state\n",
    "        dec_input_ = tf.zeros(tf.shape(inputs[0]),dtype=tf.float32)\n",
    "        dec_outputs = []\n",
    "\n",
    "        for step in range(len(inputs)):\n",
    "            if step > 0:\n",
    "                vs.reuse_variables()\n",
    "            (dec_input_, dec_state) =_dec_cell(dec_input_, dec_state)\n",
    "            dec_input_ = tf.matmul(dec_input_, dec_weight_) + dec_bias_\n",
    "            dec_outputs.append(dec_input_)\n",
    "    \n",
    "        if reverse:\n",
    "            dec_outputs = dec_outputs[::-1]\n",
    "\n",
    "        output_ = tf.transpose(tf.stack(dec_outputs), [1, 0, 2],name=\"output_\")\n",
    "\n",
    "            \n",
    "            \n",
    "    \n",
    "    input_= tf.transpose(tf.stack(inputs), [1, 0, 2],name=\"input_\")\n",
    "#    output_ = tf.transpose(output_, [0,1,2])\n",
    "    loss_ = tf.reduce_mean(tf.square(input_ - output_),name=\"loss_\")\n",
    "\n",
    "   \n",
    "    train_ = tf.train.AdamOptimizer().minimize(loss_)\n",
    "    #train_ = tf.train.GradientDescentOptimizer(0.01).minimize(loss_)\n",
    "    \n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    loss = []\n",
    "    for i in range(iteration):\n",
    "        data =[]\n",
    "        for temp in range(batch_num):\n",
    "            ind = np.random.randint(0,len(conf.sn_list)-1)\n",
    "            sub = conf.sn_list[ind]\n",
    "            data.append(sub)\n",
    "        data = np.array(data)\n",
    "\n",
    "        (loss_val, _) = sess.run([loss_, train_], {p_input: data})\n",
    "        loss.append(loss_val)\n",
    "        print('iter %d:' % (i + 1), loss_val)\n",
    "    pd.Series(loss).plot(title=\"Loss\")\n",
    "    \n",
    "\n",
    "\n",
    "    save_path = saver.save(sess, modelpath)\n",
    "    print(\"Model saved in file: %s\" % save_path) \n",
    "\n",
    "\n",
    "\"\"\"    \n",
    "    err_vec_list = []   \n",
    "    for _ in range(len(conf.vn1_list)//batch_num):\n",
    "        data =[]\n",
    "        for temp in range(batch_num):\n",
    "            ind = np.random.randint(0,len(conf.vn1_list)-1)\n",
    "            sub = conf.vn1_list[ind]\n",
    "            data.append(sub)\n",
    "        data = np.array(data)\n",
    "        (_input_, _output_) = sess.run([input_, output_], {p_input: data})\n",
    "        err_vec_list.append(abs(_input_ - _output_))\n",
    "    \n",
    "    err_vec = np.mean(np.array(err_vec_list),axis=0).reshape(batch_num,-1)\n",
    "    mu = np.mean(err_vec,axis=0)\n",
    "    sigma = np.cov(err_vec.T)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1: 10.2741\n",
      "iter 2: 7.56131\n",
      "iter 3: 4.8309\n",
      "iter 4: 5.04322\n",
      "iter 5: 4.05206\n",
      "iter 6: 3.16034\n",
      "iter 7: 3.27874\n",
      "iter 8: 2.47073\n",
      "iter 9: 2.28923\n",
      "iter 10: 1.85481\n",
      "iter 11: 1.60696\n",
      "iter 12: 1.52357\n",
      "iter 13: 1.33751\n",
      "iter 14: 1.17679\n",
      "iter 15: 1.03611\n",
      "iter 16: 0.882485\n",
      "iter 17: 0.739288\n",
      "iter 18: 0.721264\n",
      "iter 19: 0.599861\n",
      "iter 20: 0.559243\n",
      "iter 21: 0.540686\n",
      "iter 22: 0.477011\n",
      "iter 23: 0.465474\n",
      "iter 24: 0.440583\n",
      "iter 25: 0.413274\n",
      "iter 26: 0.378218\n",
      "iter 27: 0.381262\n",
      "iter 28: 0.366275\n",
      "iter 29: 0.336628\n",
      "iter 30: 0.319108\n",
      "iter 31: 0.292202\n",
      "iter 32: 0.254676\n",
      "iter 33: 0.272476\n",
      "iter 34: 0.259419\n",
      "iter 35: 0.24538\n",
      "iter 36: 0.238929\n",
      "iter 37: 0.23393\n",
      "iter 38: 0.215268\n",
      "iter 39: 0.213843\n",
      "iter 40: 0.213424\n",
      "iter 41: 0.183315\n",
      "iter 42: 0.186694\n",
      "iter 43: 0.200588\n",
      "iter 44: 0.184536\n",
      "iter 45: 0.171628\n",
      "iter 46: 0.156606\n",
      "iter 47: 0.146248\n",
      "iter 48: 0.1499\n",
      "iter 49: 0.144013\n",
      "iter 50: 0.15412\n",
      "iter 51: 0.13808\n",
      "iter 52: 0.138731\n",
      "iter 53: 0.155569\n",
      "iter 54: 0.136527\n",
      "iter 55: 0.124998\n",
      "iter 56: 0.130219\n",
      "iter 57: 0.12274\n",
      "iter 58: 0.125185\n",
      "iter 59: 0.112976\n",
      "iter 60: 0.118535\n",
      "iter 61: 0.118327\n",
      "iter 62: 0.118874\n",
      "iter 63: 0.101137\n",
      "iter 64: 0.0943669\n",
      "iter 65: 0.0939311\n",
      "iter 66: 0.103309\n",
      "iter 67: 0.09612\n",
      "iter 68: 0.113782\n",
      "iter 69: 0.0931429\n",
      "iter 70: 0.0890209\n",
      "iter 71: 0.0906375\n",
      "iter 72: 0.0801935\n",
      "iter 73: 0.0861392\n",
      "iter 74: 0.0772858\n",
      "iter 75: 0.090035\n",
      "iter 76: 0.0770229\n",
      "iter 77: 0.109758\n",
      "iter 78: 0.0792183\n",
      "iter 79: 0.0918347\n",
      "iter 80: 0.0785309\n",
      "iter 81: 0.0706495\n",
      "iter 82: 0.0719263\n",
      "iter 83: 0.0822189\n",
      "iter 84: 0.0736668\n",
      "iter 85: 0.0651544\n",
      "iter 86: 0.0637188\n",
      "iter 87: 0.0620886\n",
      "iter 88: 0.0709428\n",
      "iter 89: 0.0849261\n",
      "iter 90: 0.0587016\n",
      "iter 91: 0.0749527\n",
      "iter 92: 0.0634666\n",
      "iter 93: 0.0656465\n",
      "iter 94: 0.0663476\n",
      "iter 95: 0.0619157\n",
      "iter 96: 0.0648505\n",
      "iter 97: 0.0654196\n",
      "iter 98: 0.0635895\n",
      "iter 99: 0.0541846\n",
      "iter 100: 0.0539504\n",
      "Model saved in file: C:/Users/Bin/Desktop/Thesis/tmp/52test/LSTMAutoencoder_kdd99_v1.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22a576f28d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "p_input = tf.placeholder(tf.float32, shape=(batch_num, step_num, elem_num),name = \"p_input\")\n",
    "p_inputs = [tf.squeeze(t, [1]) for t in tf.split(p_input, step_num, 1)]\n",
    " \n",
    "ae = EncDecAD(hidden_num, p_inputs, is_training = True, decode_without_input=False)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss = []\n",
    "    for i in range(iteration):\n",
    "        data =[]\n",
    "        for temp in range(batch_num):\n",
    "            ind = np.random.randint(0,len(conf.sn_list)-1)\n",
    "            sub = conf.sn_list[ind]\n",
    "            data.append(sub)\n",
    "        data = np.array(data)\n",
    "        \n",
    "        (loss_val, _) = sess.run([ae.loss, ae.train], {p_input: data})\n",
    "        loss.append(loss_val)\n",
    "        print('iter %d:' % (i + 1), loss_val)\n",
    "    pd.Series(loss).plot(title=\"Loss\")\n",
    "\n",
    "    save_path = saver.save(sess, modelpath)\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate parameters using Vn1 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/Bin/Desktop/Thesis/tmp/52test/LSTMAutoencoder_kdd99_v1.ckpt\n",
      "Model restored.\n",
      "Initialized\n",
      "Got parameters mu and sigma.\n",
      "[ 0.14163196  0.06856354  0.14192829  0.11017958  0.14452402  0.05129714\n",
      "  0.23235789  0.12777331  0.09377929  0.19441521  0.11740766  0.10650507\n",
      "  0.07914034  0.05939821  0.29466295  0.10773213  0.1261045   0.13933644\n",
      "  0.06641228  0.16035165  0.06818345  0.33403021  0.11420295  0.15483022\n",
      "  0.39575702  0.33339575  0.33142251  0.20502384  0.11958037  0.11877743\n",
      "  0.07706015  0.14311157  0.1586957   0.08286352  0.13503458  0.07072417\n",
      "  0.13117693  0.10095475  0.16596571  0.04306875  0.26530316  0.12818624\n",
      "  0.10935734  0.20415139  0.12840058  0.12120114  0.07294317  0.06269068\n",
      "  0.29803485  0.106218    0.10211477  0.13547593  0.05797451  0.13064995\n",
      "  0.06650215  0.30300605  0.12196922  0.16918109  0.38545111  0.31563544\n",
      "  0.29414338  0.19150683  0.11854688  0.11213368  0.07585865  0.16069148\n",
      "  0.16896716  0.08983741  0.12509708  0.07494648  0.12513803  0.0891454\n",
      "  0.18359879  0.0407583   0.2789866   0.12309641  0.11756428  0.21360937\n",
      "  0.13585378  0.12690924  0.07562383  0.07186852  0.30201277  0.10503451\n",
      "  0.08408329  0.12895001  0.05347242  0.10458761  0.06056209  0.27198786\n",
      "  0.13531992  0.17070955  0.38115054  0.28740102  0.25682241  0.17113899\n",
      "  0.11440492  0.10542808  0.06969089  0.16773421  0.18536362  0.10419235\n",
      "  0.11216246  0.08775428  0.12387145  0.07892719  0.19502291  0.04522446\n",
      "  0.27966478  0.11592259  0.11870919  0.22393832  0.13516667  0.11770753\n",
      "  0.08895169  0.08798774  0.30147812  0.10297833  0.07273617  0.11453877\n",
      "  0.05152297  0.09413973  0.05075811  0.2407054   0.14898291  0.18284151\n",
      "  0.37345207  0.26659471  0.21789713  0.14690931  0.10495547  0.10117433\n",
      "  0.07114371  0.16291559  0.20109479  0.11547922  0.10095014  0.10705608\n",
      "  0.12678266  0.07557301  0.19853611  0.04279772  0.27452844  0.10876032\n",
      "  0.10965148  0.22974539  0.12942764  0.10187242  0.10722603  0.0950769\n",
      "  0.29606408  0.1073099   0.07302941  0.10090765  0.05716482  0.08894499\n",
      "  0.03911308  0.21616046  0.16219416  0.17220196  0.36466461  0.26693526\n",
      "  0.21630812  0.12166524  0.11458838  0.08847191  0.0879349   0.14804484\n",
      "  0.21534148  0.12298074  0.09254158  0.11291052  0.1336346   0.07756888\n",
      "  0.19706377  0.04037716  0.27173802  0.10395354  0.09876077  0.23421662\n",
      "  0.12445748  0.0857244   0.12120172  0.0833253   0.28783563  0.11650623\n",
      "  0.07614009  0.0854348   0.07651559  0.09909233  0.03658491  0.20361738\n",
      "  0.16343972  0.17649511  0.34900916  0.27989158  0.22227053  0.10005347\n",
      "  0.12310767  0.07385426  0.1013091   0.13067791  0.22592255  0.12177149\n",
      "  0.07945898  0.1049815   0.14299063  0.07972194  0.19331588  0.03667813\n",
      "  0.28090933  0.10216609  0.08985363  0.23586826  0.11493251  0.06346\n",
      "  0.12706479  0.06531193  0.27689806  0.1298158   0.09598614  0.08623525\n",
      "  0.09327587  0.10816658  0.04202405  0.19453499  0.1763159   0.17628203\n",
      "  0.34522083  0.30011091  0.22360358  0.08126181  0.10687965  0.0662816\n",
      "  0.10340309  0.1173449   0.21859229  0.10684855  0.07601699  0.09282212\n",
      "  0.15417248  0.07934357  0.19139785  0.03727635  0.3066681   0.10252885\n",
      "  0.08912779  0.23376942  0.09790084  0.04514983  0.12427889  0.05107794\n",
      "  0.26229697  0.13816071  0.11778736  0.08492856  0.10302609  0.12539247\n",
      "  0.04960335  0.19644393  0.18027887  0.17571041  0.34850743  0.32776368\n",
      "  0.19808204  0.06954709  0.09603817  0.07024531  0.09599047  0.11075139\n",
      "  0.19520524  0.08330354  0.0830935   0.08236828  0.16743021  0.07817583\n",
      "  0.18823515  0.03886611  0.34947887  0.10291978  0.09541526  0.22440267\n",
      "  0.07258572  0.04391371  0.11212671  0.04078379  0.2444171   0.13709952\n",
      "  0.1342808   0.09695596  0.10606565  0.12379774  0.04396548  0.20169993\n",
      "  0.17859912  0.16828264  0.35851961  0.37049544  0.17197995  0.05842853\n",
      "  0.08930369  0.08102437  0.09057003  0.11100838  0.15062469  0.06624623\n",
      "  0.09257244  0.08467118  0.17624757  0.07342522  0.17935424  0.04116767\n",
      "  0.39739802  0.10713508  0.10413405  0.20453131  0.07486136  0.05291017\n",
      "  0.09770548  0.04211319  0.22710824  0.12524365  0.13993095  0.11633021\n",
      "  0.10759841  0.10930798  0.03122736  0.19974113  0.17414019  0.15442972\n",
      "  0.37049714  0.39630544  0.13390796  0.05704782  0.09822417  0.08796877\n",
      "  0.09005676  0.12126701  0.10558113  0.06588251  0.09966116  0.10584483\n",
      "  0.17820147  0.06506934  0.16286035  0.05598002  0.43488917  0.12114283\n",
      "  0.10903929  0.17515245  0.10157128  0.06109426  0.08590309  0.05479461\n",
      "  0.20919661  0.11297794  0.13376305  0.12203164  0.12068484  0.10025714\n",
      "  0.04832876  0.19724517  0.14458919  0.18078239  0.39039534  0.41202837\n",
      "  0.11361532  0.06622749  0.09410681  0.09365644  0.09461967  0.1391445\n",
      "  0.08400667  0.08757786  0.09827884  0.13587452  0.16536073  0.06063958\n",
      "  0.1455842   0.0802813   0.45087537  0.14500247  0.10504546  0.14427651\n",
      "  0.10464893  0.08566141  0.07576013  0.07539763  0.18889448  0.10640685\n",
      "  0.11560073  0.10475522  0.1415377   0.10780118  0.08301897  0.19181105\n",
      "  0.11732175  0.16594273  0.40246111  0.43028158  0.11050262  0.06264926\n",
      "  0.08417473  0.09698194  0.10842953  0.15380655  0.09082258  0.11493794\n",
      "  0.08427368  0.15716591  0.13636099  0.06691659  0.13350317  0.10324192\n",
      "  0.44758478  0.17520618  0.09257527  0.12241776  0.09430015  0.1195425\n",
      "  0.0673378   0.10043311  0.16948023  0.12241521  0.07715359  0.07621286\n",
      "  0.17169717  0.1225322   0.1255375   0.18640289  0.1178946   0.16649717\n",
      "  0.40685844  0.45462885  0.14389624  0.05588254  0.07743673  0.08774029\n",
      "  0.12288587  0.17510276  0.10291829  0.13451843  0.06264337  0.15645455\n",
      "  0.10329901  0.09674478  0.13195783  0.1192014   0.44480842  0.20519087\n",
      "  0.08277874  0.11723276  0.10821022  0.1311281   0.06478068  0.11818328\n",
      "  0.14807273  0.17339459  0.08052684  0.07655752  0.21597111  0.17622378\n",
      "  0.16536947  0.19694909  0.14377064  0.18520132  0.40099168  0.48798046\n",
      "  0.19242676  0.07600586  0.07498001  0.08744668  0.12032609  0.20268527\n",
      "  0.11279317  0.15472965  0.04190755  0.13760377  0.07476367  0.1392782\n",
      "  0.13996619  0.12520264  0.47118512  0.22593558  0.07967114  0.12897024\n",
      "  0.12855832  0.09391566  0.06433855  0.11762585  0.1177282   0.24486169\n",
      "  0.10521461  0.10115967  0.25746807  0.25360039  0.18552423  0.21479817\n",
      "  0.22046098  0.17665021  0.38160866  0.53262192  0.23806655  0.1108848\n",
      "  0.09472805  0.11082888  0.09755965  0.21831043  0.12468964  0.18628421\n",
      "  0.03608963  0.12254987  0.07642177  0.17067118  0.13608734  0.12948832\n",
      "  0.52892232  0.23303208  0.08143049  0.13922241  0.13866177  0.09147228\n",
      "  0.05284892  0.10260876  0.07590313  0.31121805  0.11699285  0.11687491\n",
      "  0.28785086  0.30249268  0.16384344  0.22559269  0.32871562  0.1912213\n",
      "  0.36636892  0.61949456  0.25465545  0.13188858  0.09223017  0.21156123\n",
      "  0.07369074  0.22556427  0.13469441  0.23237145  0.05215632  0.13427214\n",
      "  0.1295848   0.16700333  0.09265331  0.1607908   0.59918028  0.23793685\n",
      "  0.09450833  0.11039633  0.13233337  0.19791029  0.03324543  0.09794916\n",
      "  0.04895506  0.36674303  0.09833656  0.13731202  0.284509    0.30044004\n",
      "  0.10982549  0.20612638  0.43924147  0.21213086  0.36698347  0.72169763\n",
      "  0.22718856  0.13066448  0.12467618  0.36587614  0.0768287   0.21744554\n",
      "  0.12448086  0.29121807  0.09087417  0.21020606  0.18867734  0.12519088\n",
      "  0.04192057  0.22473907  0.62025464  0.26306117  0.17534015  0.03607628\n",
      "  0.11723131  0.2800332   0.06463174  0.11464529  0.10138792  0.4369491\n",
      "  0.08622022  0.17939082  0.22428605  0.26168481  0.09770395  0.18543825\n",
      "  0.52280402  0.23845649  0.40468201  0.82933933  0.17834267  0.13723221\n",
      "  0.20543325  0.51249158  0.10255457  0.20166436  0.09788652  0.36188132\n",
      "  0.08851439  0.29277712  0.13146444  0.05330081  0.12022952  0.24398884\n",
      "  0.5489859   0.3132498   0.31340128  0.08024397  0.16134959  0.2963832\n",
      "  0.22677907  0.13702446  0.27085659  0.51346821  0.13137841  0.19109656\n",
      "  0.08192024  0.21664944  0.16257036  0.30868644  0.57080013  0.21369624\n",
      "  0.47889391  0.85759199  0.18996745  0.12977687  0.3555142   0.63864535\n",
      "  0.10163741  0.19894591  0.08915024  0.41756159  0.11901188  0.12775543\n",
      "  0.2692579   0.08535172  0.12507458  0.1704174   0.51013982  0.31006828\n",
      "  0.25052136  0.11024733  0.12775856  0.25235942  0.618231    0.11442249\n",
      "  0.56402892  0.48160425  0.18068679  0.12973624  0.39100856  0.42001852\n",
      "  0.48368248  0.73287237  0.56578302  0.20509061  0.61511517  0.72714007\n",
      "  0.37998277  0.14390057  0.43470845  0.77589977  0.14953771  0.30984759\n",
      "  0.09756976  0.44518453]\n"
     ]
    }
   ],
   "source": [
    "from Parameter_helper import Parameter_Helper\n",
    "\n",
    "para = Parameter_Helper(conf)\n",
    "\n",
    "mu, sigma = para.mu_and_sigma()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate anomaly score, get threshold t using Vn2 and Va dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = para.get_threshold(mu,sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, modelpath)  # decode_without_input=True, iter=5000\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    \n",
    "    normal_score = []\n",
    "    n_in = []\n",
    "    n_out = []\n",
    "    a_in = []\n",
    "    a_out = []\n",
    "    \n",
    "    for count in range(len(tn_list)//batch_num):\n",
    "        normal_sub = np.array(tn_list[count*batch_num:(count+1)*batch_num]) \n",
    "        (input_n, output_n) = sess.run([ae.input_, ae.output_], {p_input: normal_sub})\n",
    "        n_in.append(input_n)\n",
    "        n_out.append(output_n)\n",
    "        err_n = abs(input_n-output_n).reshape(-1,step_num)\n",
    "        err_n = err_n.reshape(batch_num,-1)\n",
    "        for batch in range(batch_num):\n",
    "           temp = np.dot( (err_n[batch] - mu ).reshape(1,-1)  , sigma.T)\n",
    "           s = np.dot(temp,(err_n[batch] - mu ))\n",
    "           normal_score.append(s[0])\n",
    "           \n",
    "    abnormal_score = []\n",
    "    for count in range(len(ta_list)//batch_num):\n",
    "        abnormal_sub = np.array(ta_list[count*batch_num:(count+1)*batch_num]) \n",
    "        (input_a, output_a) = sess.run([ae.input_, ae.output_], {p_input: abnormal_sub})\n",
    "        a_in.append(input_a)\n",
    "        a_out.append(output_a)\n",
    "        err_a = abs(input_a-output_a).reshape(-1,step_num)\n",
    "        err_a = err_a.reshape(batch_num,-1)\n",
    "        for batch in range(batch_num):\n",
    "           temp = np.dot( (err_a[batch] - mu ).reshape(1,-1)  , sigma.T)\n",
    "           s = np.dot(temp,(err_a[batch] - mu ))\n",
    "           abnormal_score.append(s[0])\n",
    "             \n",
    "\n",
    "    print('Predict result :')\n",
    "\n",
    "    pd.Series(normal_score).plot(label=\"normal_score\",figsize=(18,5))\n",
    "    pd.Series(abnormal_score).plot(label=\"abnormal_score\")\n",
    "    bar = threshold*np.ones(len(normal_score)+len(abnormal_score))\n",
    "    pd.Series(bar).plot(label=\"threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta = 0.5\n",
    "tp = np.array(abnormal_score)[np.array(abnormal_score)>threshold].size\n",
    "fp = len(abnormal_score)-tp\n",
    "fn = np.array(normal_score)[np.array(normal_score)>threshold].size\n",
    "tn = len(normal_score)- fn\n",
    "P = tp/(tp+fp)\n",
    "R = tp/(tp+fn)\n",
    "fbeta= (1+beta*beta)*P*R/(beta*beta*P+R)\n",
    "fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tp,fp,tn,fn,P,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp/fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
