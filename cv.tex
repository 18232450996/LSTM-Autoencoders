\documentclass[10ptt]{article}
\usepackage[margin=3cm]{geometry}
\usepackage{array, xcolor}
\usepackage{graphicx}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{colortbl}
\restylefloat{figure}
\title{\bfseries\Huge Bin Li}
\author{}
\date{}
\begin{document}

\begin{wrapfigure}{r}{0.25\textwidth} 
    %\centering
    \includegraphics[width=30mm,height=40mm]{photo.jpg}
\end{wrapfigure}

\begin{minipage}{0.65\textwidth}
\begingroup
\let\center\flushleft
\let\endcenter\endflushleft
\maketitle
\endgroup
\end{minipage}

\begin{minipage}[ht]{0.48\textwidth}
Mail: bin.li@t-online.de\\
Mobel: +49 176 4333 6250\\
Am Kl\"aperberg 11 App. 2.49, 30167 Hannover\\
Born on 28.05.1993 in Hebei, China\\\\

\end{minipage}

\definecolor{lightgray}{gray}{0.8}
\newcolumntype{L}{>{\raggedleft}p{0.14\textwidth}}
\newcolumntype{R}{p{0.8\textwidth}}
\newcommand\VRule{\color{cyan}\vrule width 0.8pt}

\section*{Education}
\begin{tabular}{L!{\VRule}R}
\arrayrulecolor{orange}
2016--present&{\bf MSc. in Informatics, Gottfried Wilhelm Leibniz University Hannover, Germany}\\
&Master thesis: Anomaly detection for streaming data using autoencoders\\[5pt]

2011--2015&{\bf BSc. in Network engineering, Xidian University, China}\\
&Bachelor thesis: Time series based medical big data analysis and prediction\\[5pt]

\end{tabular}

\section*{Experience}
\begin{tabular}{L!{\VRule}R}
05.2017--10.2017&{\bf Internship at Continental Automotive GmbH}\\
&The internship took place at the artificial intelligence and robotic lab of Corp. S\&T department of Continental in Regensburg. During the 6-monat intership I worked mainly on the project Anomaly detection of sensor data from IoT devices in data mining and machine learning area. The work includes: batch model development, online incremental model developent, real-time 3D object behavior visualization, project on AWS platform transplant.\\
\\[5pt]
11.2017--06.2018&{\bf Master thesis: Anomaly detection in streaming data using autoencoders}\\
&The master thesis is an extension of the anomaly detection project using more efficient methods. It's based on a state of art LSTMs-Autoencoder model. My improvement of the model is in the online incremental model updating perspective. With modification of the model gradually according to the data stream, the model shows good adaption of the stream changing (e.g. concept drift).\\
\\[5pt]
10.2016--02.2017&{\bf Project: Entity Resolution}\\
&At L3S research center. This project is aim at detecting identical but differently described entities from large amount of data in RDF form, in order to make combination and deduplication. Referred techniques are, Lucene index, NLP techniques, Clustering algorithms.
\\[5pt]

\end{tabular}

\section*{Professional skills}
\begin{tabular}{L!{\VRule}R}
\bf Big data\\&{Hadoop, Spark, Kafka, AWS}\\[5pt]

\bf Machine learning\\&{Scikit-learn, MLlib, Tensorflow}\\[5pt]

\bf Information retrieval\\&{Apache Lucene}\\[5pt]


\end{tabular}

\section*{Programming languages}
\begin{tabular}{L!{\VRule}R}
\bf Python\\&{2 years experience}\\[5pt]

\bf Java\\&{2 years experience}\\[5pt]

\end{tabular}

\section*{Languages}
\begin{tabular}{L!{\VRule}R}
\bf English&{Fluent}\\[5pt]

\bf German&{B2 level}\\[5pt]

\bf Chinese &{Native}\\[5pt]

\end{tabular}

\section*{Interested Field}
\begin{tabular}{L!{\VRule}R}
\bf Data analysis&{All kinds of data mining applications, especially online learning, time series and data stream mining}\\[10pt]

\bf Machine learning&{Using traditional machine learning model or deep learning for complicated use cases}\\[10pt]

\bf Cloud computing&{AWS architecture solution, distributed computing and streaming application}\\[20pt]

\bf NLP&{Deal with text data, information retrieval, recommand system, user modeling, semantic web }\\
\end{tabular}



\end{document}