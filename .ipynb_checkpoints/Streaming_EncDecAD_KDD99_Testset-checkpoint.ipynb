{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import queue\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "import time, threading\n",
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/Bin/Desktop/Thesis/code')\n",
    "from EncDecAD_Pred import EncDecAD_Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_num =20\n",
    "step_num = 20\n",
    "\n",
    "consumer = KafkaConsumer('kdd99stream',\n",
    "                         group_id='test-consumer-group',    # defined in consumer.properties file\n",
    "                         bootstrap_servers=['localhost:9092'],\n",
    "                         auto_offset_reset = \"earliest\")\n",
    "consumer.poll()\n",
    "#go to end of the stream\n",
    "consumer.seek_to_end()\n",
    "dataframe = pd.DataFrame()\n",
    "lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def block_generator2queue(q,stop_event):\n",
    "   \n",
    "    while not stop_event.is_set():\n",
    "        block = []\n",
    "        \n",
    "        for message in consumer:\n",
    "            if stop_event.is_set():\n",
    "                break\n",
    "            row = message.value.decode(\"utf-8\") \n",
    "            list_of_str = row.strip(\",null,null,null,null,null,null,null,null\").split(\",\")\n",
    "            list_of_num = [float(n) for n in list_of_str]\n",
    "            block.append(list_of_num)\n",
    "            if len(block)==batch_num*step_num:\n",
    "                df = pd.DataFrame(np.array(block))\n",
    "                q.put(df)\n",
    "                #print(\"Wrote a block to queue.\")\n",
    "                block.clear()\n",
    "\n",
    "def read_block_from_queue(q,stop_event):\n",
    "    global dataframe\n",
    "    \n",
    "    while not stop_event.is_set():\n",
    "        if q.empty() == False:\n",
    "            b = q.get()\n",
    "            #print(\"read a block from queue\")\n",
    "            if dataframe.size == 0:\n",
    "                dataframe = b\n",
    "            else:\n",
    "                pd.concat((dataframe,b),axis=0)\n",
    "                \n",
    "        else :\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "def prediction(stop_event):\n",
    "    global dataframe\n",
    "    pred = EncDecAD_Pred()\n",
    "    while not stop_event.is_set():\n",
    "        if dataframe.size == 0:\n",
    "            print(\"Currently not enough data for prediction.\")\n",
    "            time.sleep(15)\n",
    "        else:\n",
    "            lock.acquire()\n",
    "            try:\n",
    "                print(\"Making prediction...\")\n",
    "                pred.prediction(dataframe.iloc[:,:-1],dataframe.iloc[:,-1])\n",
    "                print(\"Finish prediction.\")\n",
    "            finally:\n",
    "                dataframe = pd.DataFrame()\n",
    "                lock.release()\n",
    "            \n",
    "def main():\n",
    "    q = queue.Queue()\n",
    "    stop_event = threading.Event()\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    write = threading.Thread(target=block_generator2queue, name='WriteThread',args=(q,stop_event,))\n",
    "    read = threading.Thread(target=read_block_from_queue, name='ReadThread',args=(q,stop_event,))\n",
    "    predict = threading.Thread(target=prediction, name='prediction',args=(stop_event,))\n",
    "   \n",
    "    try:\n",
    "        write.start()\n",
    "        read.start()\n",
    "        predict.start()\n",
    "        \n",
    "        while 1:\n",
    "            time.sleep(.1)\n",
    "    except (KeyboardInterrupt,SystemExit):\n",
    "        stop_event.set()\n",
    "        print(\"Threads closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently not enough data for prediction.\n",
      "Currently not enough data for prediction.\n",
      "Making prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread prediction:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-3-c0c9b73c9424>\", line 45, in prediction\n",
      "    pred.prediction(dataframe)\n",
      "TypeError: prediction() missing 1 required positional argument: 'label'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
