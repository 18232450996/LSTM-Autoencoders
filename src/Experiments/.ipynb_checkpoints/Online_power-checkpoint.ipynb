{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from scipy.spatial.distance import mahalanobis,euclidean\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_num = 1\n",
    "hidden_num = 15\n",
    "step_num = 84\n",
    "elem_num = 1\n",
    "init_wins = 12\n",
    "acc_size = 3*step_num #vn1 size, used for estimating mu and sigma during initialization\n",
    "power = pd.read_csv(\"C:/Users/Bin/Desktop/Thesis/dataset/power.csv\",names=[\"power_demand\",\"label\"],skiprows=step_num*init_wins)\n",
    "test_set = power.power_demand\n",
    "labels = power.label\n",
    "wins = power.shape[0]//step_num\n",
    "test_set_list = [test_set.as_matrix().reshape(wins,batch_num,step_num,elem_num)[a] for a in range(wins)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 5, 7, 26, 38]\n"
     ]
    }
   ],
   "source": [
    "# figure out anomaly windows\n",
    "buffer = [labels[i*step_num:(i+1)*step_num] for i in range(0,labels.size//step_num)]\n",
    "anomaly_index = []\n",
    "count = 0\n",
    "for buf in buffer:\n",
    "    if \"anomaly\" in buf.tolist():\n",
    "        anomaly_index.append(count)\n",
    "    else:\n",
    "        pass\n",
    "    count +=1\n",
    "print(anomaly_index)\n",
    "\n",
    "expert = [\"normal\"]*wins\n",
    "for x in anomaly_index:\n",
    "    expert[x] = \"anomaly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/Bin/Desktop/Thesis/models/power/_1_15_84_para.ckpt\n"
     ]
    }
   ],
   "source": [
    "modelpath_root =\"C:/Users/Bin/Desktop/Thesis/models/power/\"\n",
    "modelmeta_p = modelpath_root + \"_1_15_84_para.ckpt.meta\"\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph(modelmeta_p) # load trained gragh, but without the trained parameters\n",
    "saver.restore(sess,tf.train.latest_checkpoint(modelpath_root))\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "p_input = graph.get_tensor_by_name(\"p_input:0\")\n",
    "p_inputs = [tf.squeeze(t, [1]) for t in tf.split(p_input, step_num, 1)] \n",
    "p_is_training = graph.get_tensor_by_name(\"is_training_:0\")\n",
    "\n",
    "input_= tf.transpose(tf.stack(p_inputs), [1, 0, 2])    \n",
    "output_ = graph.get_tensor_by_name(\"decoder/output_:0\")\n",
    "\n",
    "tensor_mu = graph.get_tensor_by_name(\"mu:0\")\n",
    "tensor_sigma = graph.get_tensor_by_name(\"sigma:0\")\n",
    "tensor_threshold = graph.get_tensor_by_name(\"threshold:0\")\n",
    "\n",
    "loss_ = graph.get_tensor_by_name(\"decoder/loss:0\")\n",
    "train_ = graph.get_operation_by_name(\"cond/train_\")\n",
    "\n",
    "mu = sess.run(tensor_mu)\n",
    "sigma = sess.run(tensor_sigma)\n",
    "threshold = sess.run(tensor_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0854842 0.00507233 0.00671047\n"
     ]
    }
   ],
   "source": [
    "print(mu,sigma,threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Phase (With expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoring(err,mu,sigma):\n",
    "    \n",
    "    scores = []\n",
    "    for e in err:\n",
    "        scores.append(mahalanobis(e,mu,sigma))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameter(err_nbuf,err_abuf,acc_size,mu,sigma,threshold):       \n",
    "        # acc_size is the amount of data that used until now for estimating mu and sigma\n",
    "        print(\"Estimating new parameters...\")\n",
    "        \n",
    "        current_size = len(err_nbuf)*2//3\n",
    "        p = current_size/(current_size+acc_size)\n",
    "        \n",
    "        tmp_errBuffer = err_nbuf[:current_size]\n",
    "        err_vec_array = np.array(tmp_errBuffer)\n",
    "        # for univariate  data\n",
    "        __mu = np.mean(err_vec_array.ravel())\n",
    "        mu_new = p*__mu + (1-p)*mu\n",
    "\n",
    "        __sigma =np.var(err_vec_array.ravel())\n",
    "        sigma_new = p*__sigma + (1-p)*sigma + p*(1-p)*(mu-mu_new)*(mu-mu_new)\n",
    "        \n",
    "        \n",
    "        _score_n = scoring(np.array(err_nbuf[current_size:]).reshape(-1,elem_num),mu_new,sigma_new) \n",
    "        _score_a = scoring(np.array(err_abuf).reshape(-1,elem_num),mu_new,sigma_new) \n",
    "        \n",
    "        scores = pd.Series(_score_n + _score_a)\n",
    "        label = pd.Series( [\"normal\"]*len(_score_n) + [\"anomaly\"]*len(_score_a))\n",
    "        \n",
    "        upper = np.median(np.array(_score_a))\n",
    "        lower = np.median(np.array(_score_n)) \n",
    "        scala = 20\n",
    "        delta = (upper-lower) / scala\n",
    "        candidate = lower\n",
    "        __threshold = 0\n",
    "        result = 0\n",
    "        print(np.array(_score_a).max(),np.array(_score_n).min())\n",
    "        for _ in range(scala):\n",
    "            r = evaluate(candidate,scores,label)\n",
    "            if r > result:\n",
    "                result = r \n",
    "                __threshold = candidate\n",
    "            candidate += delta \n",
    "\n",
    "            \n",
    "        threshold_new = __threshold\n",
    "        print(\"New parameters learned!\")\n",
    "        \n",
    "        return mu_new,sigma_new,threshold_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(threoshld,scores,label):\n",
    "\n",
    "    beta = 1\n",
    "    tp = len(set(scores[ scores > threshold].index) & set( label[label=='anomaly'].index))\n",
    "    fn = len(set(scores[ scores > threshold].index) & set(label[label=='normal'].index))\n",
    "    fp = len(set(scores[ scores <= threshold].index) & set( label[label=='anomaly'].index))\n",
    "    tn = len(set(scores[ scores <= threshold].index) & set(label[label=='normal'].index))\n",
    "\n",
    "    \n",
    "\n",
    "    if tp == 0: \n",
    "        print(\"TP is 0.\")\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    P = tp/(tp+fp) # reduce the number of didn't detected anomaly\n",
    "    R = tp/(tp+fn) # recuce the number of normal points that predicted as abnormal\n",
    "    fbeta= (1+beta*beta)*P*R/(beta*beta*P+R)\n",
    "    return fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc(fpr,tpr,auc):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' %auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "n_buf = []\n",
    "a_buf = []\n",
    "\n",
    "y = []\n",
    "output=[]\n",
    "box = []\n",
    "err_nbuf = []\n",
    "err_abuf = []\n",
    "all_scores = []\n",
    "\n",
    "for l in labels:\n",
    "    if l == \"normal\":\n",
    "        y +=[0]\n",
    "    else: \n",
    "        y +=[1]\n",
    "for data in test_set_list:\n",
    "    \n",
    "        prediction = []\n",
    "        \n",
    "        (input_n, output_n) = sess.run([input_, output_], {p_input: data, p_is_training: False})\n",
    "\n",
    "        err = abs(input_n-output_n).reshape(-1,elem_num)\n",
    "        \n",
    "        box.append(err.reshape(-1,))\n",
    "        \n",
    "        scores = scoring(err,mu,sigma)\n",
    "        scores = pd.Series(scores)\n",
    "        \n",
    "        all_scores.append(scores)\n",
    "        #output += [x for x in scores]\n",
    "        output +=[scores[scores>threshold].size]\n",
    "        pred = [scores[b*step_num:(b+1)*step_num] for b in range(batch_num)]\n",
    "        label = [expert[count*batch_num+b]for b in range(batch_num)]\n",
    "        e = [err.ravel()[b*step_num:(b+1)*step_num] for b in range(batch_num)]\n",
    "        for index,value in enumerate(pred):\n",
    "            if value[value>threshold].size>=5: \n",
    "                if label[index] == \"anomaly\":\n",
    "                    print(\"TP\")                 \n",
    "                    a_buf.append(data[index])\n",
    "                    err_abuf.append(e[index])\n",
    "                else:\n",
    "                    print(\"FP\")\n",
    "                    err_nbuf.append(e[index])\n",
    "                    n_buf.append(data[index])\n",
    "                    \n",
    "            else:               \n",
    "                if label[index] == \"anomaly\":             \n",
    "                    print(\"FN\")\n",
    "                    a_buf.append(data[index])\n",
    "                    err_abuf.append(e[index])\n",
    "                else:\n",
    "                    err_nbuf.append(e[index])\n",
    "                    print(\"TN\")\n",
    "        count +=1\n",
    "        \n",
    "\n",
    "        \n",
    "        if len(n_buf)>=3:\n",
    "            print(\"retrain...\")\n",
    "            loss_list_all=[]\n",
    "\n",
    "            datalist = np.array(n_buf).reshape(-1,batch_num,step_num,elem_num)\n",
    "            \n",
    "            for i in range(50):\n",
    "                \n",
    "                loss_list=[]\n",
    "                for data in datalist:\n",
    "                    (loss, _) = sess.run([loss_, train_], {p_input: data,p_is_training : True})\n",
    "                    loss_list.append(loss)\n",
    "                #print('Retrain-iter %d:' % (i + 1), np.array(loss_list).mean())\n",
    "                loss_list_all.append( np.array(loss_list).mean()) \n",
    "                \n",
    "            mu,sigma,threshold = update_parameter(err_nbuf,err_abuf,acc_size,mu,sigma,threshold)\n",
    "            print(mu,sigma,threshold)\n",
    "            pd.Series(loss_list_all).plot(title=\"Loss\")\n",
    "            n_buf = []\n",
    "            err_buf = []\n",
    "                \n",
    "fpr, tpr, thresholds = metrics.roc_curve(expert, output, pos_label=\"anomaly\")\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "#print(fpr,tpr,thresholds,auc)\n",
    "plot_roc(fpr,tpr,auc)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 5.5)\n",
    "ax.boxplot(box)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
