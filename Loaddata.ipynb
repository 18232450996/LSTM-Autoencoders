{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Loaddata(object):\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset = dataset\n",
    "        self.folder = \"C:/Users/Bin/Documents/Datasets/\"\n",
    "        self.kdd99_col_name_suffix = \"KDD99/columns.txt\"\n",
    "        self.kdd99_dataset_suffix = \"KDD99/kddcup.data_10_percent_corrected\"\n",
    "        self.power_demand_suffix = \"EncDec-AD dataset/power_data.txt\"\n",
    "        \n",
    "    def read(self):\n",
    "        if self.dataset == \"kdd99\":\n",
    "            with open(self.folder+self.kdd99_col_name_suffix) as col_file:\n",
    "                line = col_file.readline()\n",
    "            columns = line.split('.')\n",
    "            col_names = []\n",
    "            col_types = []\n",
    "            for col in columns:\n",
    "                col_names.append(col.split(': ')[0].strip())\n",
    "                col_types.append(col.split(': ')[1])\n",
    "            col_names.append(\"label\")\n",
    "            df = pd.read_csv(self.folder+self.kdd99_dataset_suffix,names=col_names)\n",
    "            data = df.iloc[:,np.array(pd.Series(col_types)==\"continuous\")].as_matrix()   #Select only numeric features\n",
    "            label = df.iloc[:,-1]\n",
    "\n",
    "            # Scaling\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(data)\n",
    "            data = scaler.transform(data) \n",
    "            \n",
    "            return data\n",
    "        \n",
    "        elif self.dataset == \"power_demand\":\n",
    "            power = pd.read_csv(\"C:/Users/Bin/Documents/Datasets/EncDec-AD dataset/power_data.txt\",names=[\"power_demand\"])\n",
    "            # downsample the dataset by 8 to obtain non-overlapping sequences with L=84 such that each window corresponds to one week\n",
    "            sub_power = pd.Series(power[490:].reset_index(drop=True)[\"power_demand\"])\n",
    "            index = [8*t for t in range(sub_power.shape[0]//8 +1)]\n",
    "            sub_power = sub_power[index].reset_index(drop=True)  # shape(4319,)\n",
    "            #Scaling\n",
    "            sub_power = sub_power.reshape(-1, 1)\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(sub_power)\n",
    "            sub_power = scaler.transform(sub_power) \n",
    "            \n",
    "            return sub_power\n",
    "        \n",
    "        elif self.dataset == \"space_shuttle\":\n",
    "            tek17 = pd.read_csv(\"C:/Users/Bin/Documents/Datasets/EncDec-AD dataset/TEK17.txt\",header=None)\n",
    "            tek16 = pd.read_csv(\"C:/Users/Bin/Documents/Datasets/EncDec-AD dataset/TEK16.txt\",header=None)\n",
    "            tek14 = pd.read_csv(\"C:/Users/Bin/Documents/Datasets/EncDec-AD dataset/TEK14.txt\",header=None)\n",
    "            tek = pd.concat([tek14,tek16,tek17],axis=0).reset_index(drop=True)\n",
    "            # downsample the dataset by 3 \n",
    "            sub_tek = pd.Series(tek[0])\n",
    "            index = [3*t for t in range(tek.shape[0]//3)]\n",
    "            sub_tek = sub_tek[index].reset_index(drop=True)\n",
    "            #Scaling\n",
    "            sub_tek = sub_tek.reshape(-1, 1)\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(sub_tek)\n",
    "            sub_tek = scaler.transform(sub_tek) \n",
    "            #Applying sliding window, window length 1500/3=500, step_size 500/3= 166\n",
    "            STEP_SIZE = 500//3 # downsampled by 3\n",
    "            WINDOW_LENGTH = 1500//3   # downsampled by 3\n",
    "            t = 1\n",
    "            sequence = sub_tek[:WINDOW_LENGTH]\n",
    "            while t*STEP_SIZE+WINDOW_LENGTH <=sub_tek.size:\n",
    "                sequence = np.concatenate((sequence,sub_tek[t*STEP_SIZE:t*STEP_SIZE+WINDOW_LENGTH]))\n",
    "                t = t+1\n",
    "            return sequence\n",
    "            \n",
    "        else:\n",
    "            print(\"Wrong dataset name\")\n",
    "            return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
